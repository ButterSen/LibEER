import numpy as np
import torch
import torch.nn as nn
import torch.utils.data
from torch.utils.data import RandomSampler, SequentialSampler, DataLoader
import torch.optim as optim
from data_utils.constants.deap import DEAP_CHANNEL_NAME
from data_utils.constants.seed import SEED_CHANNEL_NAME

from tqdm import tqdm
import yaml

from utils.store import save_state
from utils.metric import Metric

# code reference : https://github.com/yi-ding-cs/TSception
# TSception: Capturing Temporal Dynamics and Spatial Asymmetry From EEG for Emotion Recognition
# paper link : https://ieeexplore.ieee.org/document/9762054
# Y. Ding, N. Robinson, S. Zhang, Q. Zeng and C. Guan, "TSception: Capturing Temporal Dynamics and Spatial Asymmetry From EEG for Emotion Recognition," in IEEE Transactions on Affective Computing, vol. 14, no. 3, pp. 2238-2250, 1 July-Sept. 2023, doi: 10.1109/TAFFC.2022.3169001.

class TSception(nn.Module):
    def conv_block(self, in_chan, out_chan, kernel, step, pool):
        return nn.Sequential(
            nn.Conv2d(in_channels=in_chan, out_channels=out_chan,
                      kernel_size=kernel, stride=step),
            nn.LeakyReLU(),
            nn.AvgPool2d(kernel_size=(1, pool), stride=(1, pool)))

    def __init__(self, num_electrodes, num_datapoints, num_classes, inception_window=None, num_T=15, num_S=15, hidden=32, dropout_rate=0.5):
        # input_size: 1 x EEG channel x datapoint
        super(TSception, self).__init__()
        if num_electrodes == 62:
            # seed
            num_electrodes = 54
        elif num_electrodes == 32:
            num_electrodes = 28
        if inception_window is not None:
            self.inception_window = inception_window
        else:
            self.inception_window = [0.5, 0.25, 0.125]
        self.pool = 8
        # by setting the convolutional kernel being (1,lenght) and the strids being 1 we can use conv2d to
        # achieve the 1d convolution operation
        self.Tception1 = self.conv_block(1, num_T, (1, int(self.inception_window[0] * num_datapoints)), 1, self.pool)
        self.Tception2 = self.conv_block(1, num_T, (1, int(self.inception_window[1] * num_datapoints)), 1, self.pool)
        self.Tception3 = self.conv_block(1, num_T, (1, int(self.inception_window[2] * num_datapoints)), 1, self.pool)

        self.Sception1 = self.conv_block(num_T, num_S, (int(num_electrodes), 1), 1, int(self.pool*0.25))
        self.Sception2 = self.conv_block(num_T, num_S, (int(num_electrodes * 0.5), 1), (int(num_electrodes * 0.5), 1),
                                         int(self.pool*0.25))
        self.fusion_layer = self.conv_block(num_S, num_S, (3, 1), 1, 4)
        self.BN_t = nn.BatchNorm2d(num_T)
        self.BN_s = nn.BatchNorm2d(num_S)
        self.BN_fusion = nn.BatchNorm2d(num_S)

        self.fc = nn.Sequential(
            nn.Linear(num_S, hidden),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(hidden, num_classes)
        )

    def forward(self, x):
        x = x.unsqueeze(1)
        y = self.Tception1(x)
        out = y
        y = self.Tception2(x)
        out = torch.cat((out, y), dim=-1)
        y = self.Tception3(x)
        out = torch.cat((out, y), dim=-1)
        out = self.BN_t(out)
        z = self.Sception1(out)
        out_ = z
        z = self.Sception2(out)
        out_ = torch.cat((out_, z), dim=2)
        out = self.BN_s(out_)
        out = self.fusion_layer(out)
        out = self.BN_fusion(out)
        out = torch.squeeze(torch.mean(out, dim=-1), dim=-1)
        out = self.fc(out)
        return out


def generate_TS_channel_order(original_order: list):
    """
        This function will generate the channel order for TSception
        Parameters
        ----------
        original_order: list of the channel names

        Returns
        -------
        TS: list of channel names which is for TSception
        """
    chan_name, chan_num, chan_final = [], [], []
    for channel in original_order:
        chan_name_len = len(channel)
        k = 0
        for s in [*channel[:]]:
            if s.isdigit():
                k += 1
        if k != 0:
            chan_name.append(channel[:chan_name_len - k])
            chan_num.append(int(channel[chan_name_len - k:]))
            chan_final.append(channel)
    chan_pair = []
    for ch, id in enumerate(chan_num):
        if id % 2 == 0:
            chan_pair.append(chan_name[ch] + str(id - 1))
        else:
            chan_pair.append(chan_name[ch] + str(id + 1))
    chan_no_duplicate = []
    [chan_no_duplicate.extend([f, chan_pair[i]]) for i, f in enumerate(chan_final) if f not in chan_no_duplicate]
    chans = chan_no_duplicate[0::2] + chan_no_duplicate[1::2]
    indexes = [original_order.index(c) for c in chans]
    return np.array(indexes)